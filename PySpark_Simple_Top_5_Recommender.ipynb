{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark Simple Top 5 Recommender",
      "provenance": [],
      "authorship_tag": "ABX9TyNiHhldX+7VBTWm/c/3jMth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSBX5420/team-mount-massive/blob/master/PySpark_Simple_Top_5_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAsP28t8ROt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "3a588d98-bada-46d9-ae4d-11c2f8309382"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 62kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=63332ed1ab799d3c63c5b851677111e72ad00141f4adb0e5c0398690571e5a60\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0I-QY3scsiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "3342577a-090b-4003-c8e4-5f43341b9100"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj5krNwdP3zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ead0e5be-8eb5-4523-cc73-55b8f0d9dadb"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext()\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "spark=SparkSession.builder.appName('Recommend_Function').getOrCreate()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fb11f6159746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-6-8b8234555f42>:6 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdfqOAND7UH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCqLQ6IJSZBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "eb704301-c9ec-46af-b3a9-d30c8a0b2404"
      },
      "source": [
        "movies = spark.read.csv('drive/My Drive/Data/sample_movies_single.csv', header =True, inferSchema=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+\n",
            "|  titleId|ordering|               title|region|language|   types|attributes|isOriginalTitle|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|averageRating|numVotes|\n",
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+\n",
            "|tt0000012|       7|L'arrivée d'un tr...|    \\N|      \\N|original|        \\N|              1|tt0000012|    short|The Arrival of a ...|L'arrivée d'un tr...|    0.0|     1896|     \\N|             1|Action,Documentar...|          7.4|  9435.0|\n",
            "|tt0000582|       4|             Ben Hur|    \\N|      \\N|original|        \\N|              1|tt0000582|    short|             Ben Hur|             Ben Hur|    0.0|     1907|     \\N|            15|         Drama,Short|          5.1|   555.0|\n",
            "|tt0001013|       1|  The Red Man's View|    \\N|      \\N|original|        \\N|              1|tt0001013|    short|  The Red Man's View|  The Red Man's View|    0.0|     1909|     \\N|            14|       Short,Western|          5.9|   283.0|\n",
            "|tt0011545|       8|  Oranges and Lemons|    \\N|      \\N|original|        \\N|              1|tt0011545|    short|  Oranges and Lemons|  Oranges and Lemons|    0.0|     1923|     \\N|            12|        Comedy,Short|          5.8|   367.0|\n",
            "|tt0013951|       7|   The Covered Wagon|    \\N|      \\N|original|        \\N|              1|tt0013951|    movie|   The Covered Wagon|   The Covered Wagon|    0.0|     1923|     \\N|            98|Adventure,Romance...|          6.5|   470.0|\n",
            "|tt0014416|       1|              Rosita|    \\N|      \\N|original|        \\N|              1|tt0014416|    movie|              Rosita|              Rosita|    0.0|     1923|     \\N|            90|      Comedy,Romance|          6.5|   252.0|\n",
            "|tt0014497|       4|      Souls for Sale|    \\N|      \\N|original|        \\N|              1|tt0014497|    movie|      Souls for Sale|      Souls for Sale|    0.0|     1923|     \\N|            90|Comedy,Drama,Romance|          7.0|   770.0|\n",
            "|tt0015175|      11|Die Nibelungen: S...|    \\N|      \\N|original|        \\N|              1|tt0015175|    movie|Die Nibelungen: S...|Die Nibelungen: S...|    0.0|     1924|     \\N|           143|Adventure,Drama,F...|          8.1|  4801.0|\n",
            "|tt0015648|      41|Bronenosets Potemkin|    \\N|      \\N|original|        \\N|              1|tt0015648|    movie| Battleship Potemkin|Bronenosets Potemkin|    0.0|     1925|     \\N|            75|Drama,History,Thr...|          8.0| 49224.0|\n",
            "|tt0016461|       9|         Tumbleweeds|    \\N|      \\N|original|        \\N|              1|tt0016461|    movie|         Tumbleweeds|         Tumbleweeds|    0.0|     1925|     \\N|            78|             Western|          6.5|   511.0|\n",
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKg1Hei0Azwl",
        "colab_type": "text"
      },
      "source": [
        "Load in data and create a copy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9etHp-5A3Xf",
        "colab_type": "text"
      },
      "source": [
        "Create a new Weighted Rating Column in data copy using formula cited to be from IMDB on Kaggle (though IMDB says it keeps its weighted rating formula private to maintain efficacy). This formula takes number of votes for the movie, the average rating over all movies, the average rating for the movie, and an inputed value representing the number of votes requred to make the list (I chose movies over the 10th percentile since we already created a cutoff in the data cleaning process).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpAXXhnDWbFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaHqaqHbeYe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QVs_oTIWneI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import udf, col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcjXtAbJqnde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = movies.groupBy().avg(\"averageRating\").take(1)[0][0]\n",
        "movies = movies.withColumn(\"AverageTotalVotes\", lit(mean))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apUE3MzVWcpc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "a5de3027-b06e-491e-be18-859f5583135d"
      },
      "source": [
        "movies = movies.withColumn(\"WeightedRating\", lit(0).cast(IntegerType()))\n",
        "movies = movies.withColumn(\"MinimumVotes\", lit(100).cast(IntegerType()))\n",
        "movies.show(10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+--------------+------------+-----------------+\n",
            "|  titleId|ordering|               title|region|language|   types|attributes|isOriginalTitle|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|averageRating|numVotes|WeightedRating|MinimumVotes|AverageTotalVotes|\n",
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+--------------+------------+-----------------+\n",
            "|tt0000012|       7|L'arrivée d'un tr...|    \\N|      \\N|original|        \\N|              1|tt0000012|    short|The Arrival of a ...|L'arrivée d'un tr...|    0.0|     1896|     \\N|             1|Action,Documentar...|          7.4|  9435.0|             0|         100|6.376230569948188|\n",
            "|tt0000582|       4|             Ben Hur|    \\N|      \\N|original|        \\N|              1|tt0000582|    short|             Ben Hur|             Ben Hur|    0.0|     1907|     \\N|            15|         Drama,Short|          5.1|   555.0|             0|         100|6.376230569948188|\n",
            "|tt0001013|       1|  The Red Man's View|    \\N|      \\N|original|        \\N|              1|tt0001013|    short|  The Red Man's View|  The Red Man's View|    0.0|     1909|     \\N|            14|       Short,Western|          5.9|   283.0|             0|         100|6.376230569948188|\n",
            "|tt0011545|       8|  Oranges and Lemons|    \\N|      \\N|original|        \\N|              1|tt0011545|    short|  Oranges and Lemons|  Oranges and Lemons|    0.0|     1923|     \\N|            12|        Comedy,Short|          5.8|   367.0|             0|         100|6.376230569948188|\n",
            "|tt0013951|       7|   The Covered Wagon|    \\N|      \\N|original|        \\N|              1|tt0013951|    movie|   The Covered Wagon|   The Covered Wagon|    0.0|     1923|     \\N|            98|Adventure,Romance...|          6.5|   470.0|             0|         100|6.376230569948188|\n",
            "|tt0014416|       1|              Rosita|    \\N|      \\N|original|        \\N|              1|tt0014416|    movie|              Rosita|              Rosita|    0.0|     1923|     \\N|            90|      Comedy,Romance|          6.5|   252.0|             0|         100|6.376230569948188|\n",
            "|tt0014497|       4|      Souls for Sale|    \\N|      \\N|original|        \\N|              1|tt0014497|    movie|      Souls for Sale|      Souls for Sale|    0.0|     1923|     \\N|            90|Comedy,Drama,Romance|          7.0|   770.0|             0|         100|6.376230569948188|\n",
            "|tt0015175|      11|Die Nibelungen: S...|    \\N|      \\N|original|        \\N|              1|tt0015175|    movie|Die Nibelungen: S...|Die Nibelungen: S...|    0.0|     1924|     \\N|           143|Adventure,Drama,F...|          8.1|  4801.0|             0|         100|6.376230569948188|\n",
            "|tt0015648|      41|Bronenosets Potemkin|    \\N|      \\N|original|        \\N|              1|tt0015648|    movie| Battleship Potemkin|Bronenosets Potemkin|    0.0|     1925|     \\N|            75|Drama,History,Thr...|          8.0| 49224.0|             0|         100|6.376230569948188|\n",
            "|tt0016461|       9|         Tumbleweeds|    \\N|      \\N|original|        \\N|              1|tt0016461|    movie|         Tumbleweeds|         Tumbleweeds|    0.0|     1925|     \\N|            78|             Western|          6.5|   511.0|             0|         100|6.376230569948188|\n",
            "+---------+--------+--------------------+------+--------+--------+----------+---------------+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+-------------+--------+--------------+------------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcuvofulocLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAAv60MH_2Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted(v, m, C, R) : \n",
        "  return (v/(v+m) * R) + (m/(m+v) * C)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_qhWzi3rEWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_udf = udf(weighted, IntegerType())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQOJM8ZproRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = movies.withColumn('WeightedRating', weighted_udf('numVotes', 'MinimumVotes', 'AverageTotalVotes', 'averageRating'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT7sGShWshZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bebcd9c-d43a-44aa-a07a-474a7a50d7b3"
      },
      "source": [
        "movies.show(10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o927.showString.\n: java.lang.IllegalArgumentException: Unsupported class file major version 55\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:820)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1.apply(RDD.scala:819)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.mapPartitions(RDD.scala:819)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.doExecute(EvalPythonExec.scala:89)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-89cc33d10ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 55'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWew8V2NBp-Z",
        "colab_type": "text"
      },
      "source": [
        "Create a function that takes three parameters: genre, type, and age of film. This function cycles through films meeting the criteria, and produces a top 5 list based on highest weighted rating. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDWJZU3d-j-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "9bc73f99-2a0d-48b1-f000-2e3fe737a7a4"
      },
      "source": [
        "def recommend(genrechoice : str) :\n",
        "  PossMovie = movies.filter(movies.genres.like(genrechoice)\n",
        "  CASE \n",
        "    WHEN (agechoice = 'New') THEN PossMovie = PossMovie.filter(movies.startYear >= 2000)\n",
        "    WHEN (agechoice = 'Old') THEN PossMovie = PossMovie.filter(movies.startYear < 2000) \n",
        "    ELSE PossMovie = PossMovie\n",
        "  END\n",
        "  PossMovie = PossMovie.select('title', 'genres', 'startYear', 'titleType', 'WeightedRating')\n",
        "  PossMovie.show(10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-ad7904ff83ae>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    PossMovie = movies.filter(movies.genres.like(genrechoice)                            filter(movies.titleType.contains(typechoice)\u001b[0m\n\u001b[0m                                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7MNzqB8hbVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  Ordered = PossMovie.sort_values(by=\"WeightedRating\", ascending = False) \n",
        "  Ordered = Ordered[['title', 'genres', 'titleType', 'startYear', 'WeightedRating']]\n",
        "  Top5 = Ordered[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R38g5EKGB2AM",
        "colab_type": "text"
      },
      "source": [
        "Test function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yQjoT9-xRR",
        "colab_type": "code",
        "outputId": "07bce9d4-a239-4a59-aff6-c7634755940e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "recommend('Comedy', 'movie', 'New')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>titleType</th>\n",
              "      <th>startYear</th>\n",
              "      <th>WeightedRating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>Marmoulak</td>\n",
              "      <td>Comedy,Drama</td>\n",
              "      <td>movie</td>\n",
              "      <td>2004</td>\n",
              "      <td>8.499704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>Dil Chahta Hai</td>\n",
              "      <td>Comedy,Drama,Romance</td>\n",
              "      <td>movie</td>\n",
              "      <td>2001</td>\n",
              "      <td>8.099953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>Guardians of the Galaxy</td>\n",
              "      <td>Action,Adventure,Comedy</td>\n",
              "      <td>movie</td>\n",
              "      <td>2014</td>\n",
              "      <td>7.999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>Zootopia</td>\n",
              "      <td>Adventure,Animation,Comedy</td>\n",
              "      <td>movie</td>\n",
              "      <td>2016</td>\n",
              "      <td>7.999993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>En man som heter Ove</td>\n",
              "      <td>Comedy,Drama,Romance</td>\n",
              "      <td>movie</td>\n",
              "      <td>2015</td>\n",
              "      <td>7.699945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        title  ... WeightedRating\n",
              "769                 Marmoulak  ...       8.499704\n",
              "663            Dil Chahta Hai  ...       8.099953\n",
              "1135  Guardians of the Galaxy  ...       7.999997\n",
              "1248                 Zootopia  ...       7.999993\n",
              "1337     En man som heter Ove  ...       7.699945\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}