{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting a movie's sucess - Logistic & Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('movies_model').getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('test_movies_single.csv',inferSchema=True,header=True)\n",
    "df2 = spark.read.csv('sample_movies_single.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = df.union(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the columns that we want to use as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.select('titleType','isAdult','startYear','runtimeMinutes','genres','averageRating','numVotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+--------------+--------------------+-------------+--------+\n",
      "|titleType|isAdult|startYear|runtimeMinutes|              genres|averageRating|numVotes|\n",
      "+---------+-------+---------+--------------+--------------------+-------------+--------+\n",
      "|    short|    0.0|     1901|             5|         Drama,Short|          6.1|   509.0|\n",
      "|    short|    0.0|     1914|            16|        Comedy,Short|          5.7|   751.0|\n",
      "|    short|    0.0|     1914|            16|        Comedy,Short|          6.0|  1018.0|\n",
      "|    movie|    0.0|     1917|            70|Adventure,Comedy,...|          5.7|   712.0|\n",
      "|    movie|    0.0|     1917|            57|             Western|          6.2|   335.0|\n",
      "|    movie|    0.0|     1917|            48|           Drama,War|          7.4|  1384.0|\n",
      "|    movie|    0.0|     1918|            62|       Drama,Romance|          5.4|   270.0|\n",
      "|    short|    0.0|     1919|            12|Comedy,Short,Western|          6.1|   699.0|\n",
      "|    movie|    0.0|     1921|           117|        Comedy,Drama|          6.6|  1191.0|\n",
      "|    movie|    0.0|     1921|            47|              Comedy|          7.0|   901.0|\n",
      "+---------+-------+---------+--------------+--------------------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new binary Success column where if the average rating is greater than 7, its a success, and if it's less than its not successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+--------------+--------------------+-------------+--------+-------+\n",
      "|titleType|isAdult|startYear|runtimeMinutes|              genres|averageRating|numVotes|Success|\n",
      "+---------+-------+---------+--------------+--------------------+-------------+--------+-------+\n",
      "|    short|    0.0|     1901|             5|         Drama,Short|          6.1|   509.0|      0|\n",
      "|    short|    0.0|     1914|            16|        Comedy,Short|          5.7|   751.0|      0|\n",
      "|    short|    0.0|     1914|            16|        Comedy,Short|          6.0|  1018.0|      0|\n",
      "|    movie|    0.0|     1917|            70|Adventure,Comedy,...|          5.7|   712.0|      0|\n",
      "|    movie|    0.0|     1917|            57|             Western|          6.2|   335.0|      0|\n",
      "+---------+-------+---------+--------------+--------------------+-------------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "movies = movies.withColumn('Success', f.when(f.col('averageRating') >= 7.0, 1).otherwise(0))\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the average rating column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop('averageRating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the video game title as it doesn't have a run time, and any special characters in the runtime column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.filter(movies.titleType !='videoGame')   \n",
    "movies = movies.filter(movies.runtimeMinutes !='\\\\N') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the runtime column is an integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "movies = movies.withColumn(\"runtimeMinutes\", movies[\"runtimeMinutes\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the string columns to categorical variables that can be used as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['genres','titleType','startYear']\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = i, outputCol = i + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[i + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a label column that has a success/failure of a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcolumn = StringIndexer(inputCol = 'Success', outputCol = 'Label')\n",
    "stages += [labelcolumn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the numerical columns, we can convert them to a vector and then add it to the existing categorical variables that were created for the initial columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericColumns = ['runtimeMinutes','numVotes','isAdult']\n",
    "assembler = [c + \"classVec\" for c in categoricalColumns] + numericColumns\n",
    "assembler = VectorAssembler(inputCols=assembler, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new movies dataframe should have the existing columns, along with the newly created columns (Features/Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- isAdult: double (nullable = true)\n",
      " |-- startYear: integer (nullable = true)\n",
      " |-- runtimeMinutes: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- numVotes: double (nullable = true)\n",
      " |-- Success: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(movies)\n",
    "movies = pipelineModel.transform(movies)\n",
    "selectedColumns = ['label', 'features'] + columns\n",
    "movies = movies.select(selectedColumns)\n",
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+-------+---------+--------------+--------------------+--------+-------+\n",
      "|label|            features|titleType|isAdult|startYear|runtimeMinutes|              genres|numVotes|Success|\n",
      "+-----+--------------------+---------+-------+---------+--------------+--------------------+--------+-------+\n",
      "|  0.0|(553,[78,435,524,...|    short|    0.0|     1901|             5|         Drama,Short|   509.0|      0|\n",
      "|  0.0|(553,[46,435,540,...|    short|    0.0|     1914|            16|        Comedy,Short|   751.0|      0|\n",
      "|  0.0|(553,[46,435,540,...|    short|    0.0|     1914|            16|        Comedy,Short|  1018.0|      0|\n",
      "|  0.0|(553,[55,432,532,...|    movie|    0.0|     1917|            70|Adventure,Comedy,...|   712.0|      0|\n",
      "|  0.0|(553,[34,432,532,...|    movie|    0.0|     1917|            57|             Western|   335.0|      0|\n",
      "|  1.0|(553,[21,432,532,...|    movie|    0.0|     1917|            48|           Drama,War|  1384.0|      1|\n",
      "|  0.0|(553,[2,432,546,5...|    movie|    0.0|     1918|            62|       Drama,Romance|   270.0|      0|\n",
      "|  0.0|(553,[375,435,543...|    short|    0.0|     1919|            12|Comedy,Short,Western|   699.0|      0|\n",
      "|  0.0|(553,[3,432,535,5...|    movie|    0.0|     1921|           117|        Comedy,Drama|  1191.0|      0|\n",
      "|  1.0|(553,[1,432,535,5...|    movie|    0.0|     1921|            47|              Comedy|   901.0|      1|\n",
      "+-----+--------------------+---------+-------+---------+--------------+--------------------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can split the data into training & test sets and then start off with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = movies.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "pred_train = lrModel.transform(train)\n",
    "pred_test = lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the probability of a success/failure by including our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "|titleType|numVotes|runTimeMinutes|       genres|Success|prediction|         probability|\n",
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "|    movie|   441.0|            78|        Drama|      0|       0.0|[0.82291682553622...|\n",
      "|    movie|   585.0|            90|        Drama|      0|       0.0|[0.72966698771529...|\n",
      "|    movie|   290.0|            98|        Drama|      0|       0.0|[0.69987410259675...|\n",
      "|    movie|  2293.0|           100|        Drama|      0|       0.0|[0.73743796965920...|\n",
      "|    movie|   789.0|           106|        Drama|      0|       0.0|[0.77741545603628...|\n",
      "|    movie|   270.0|           106|        Drama|      0|       0.0|[0.67796490943905...|\n",
      "|    movie|   464.0|            85|        Drama|      0|       0.0|[0.73122953424152...|\n",
      "|    movie|   772.0|            87|        Drama|      0|       0.0|[0.81201396509627...|\n",
      "|    movie|  3594.0|            90|        Drama|      0|       0.0|[0.79686683040957...|\n",
      "|    movie| 94563.0|           133|        Drama|      0|       1.0|[0.32552495331038...|\n",
      "|    movie|   547.0|            95|        Drama|      0|       0.0|[0.73954107322533...|\n",
      "|    movie|  2086.0|           108|        Drama|      0|       0.0|[0.68511943963875...|\n",
      "|    movie|   414.0|           131|        Drama|      0|       1.0|[0.46658857659640...|\n",
      "|    movie|   300.0|            95|        Drama|      0|       1.0|[0.44910789693265...|\n",
      "|    movie|   352.0|           119|        Drama|      0|       1.0|[0.29443508412612...|\n",
      "| tvSeries|  1504.0|            60|        Drama|      0|       1.0|[0.11874391100952...|\n",
      "|  tvMovie|   308.0|            84|        Drama|      0|       0.0|[0.78380004699944...|\n",
      "|  tvMovie|   312.0|            80|        Drama|      0|       0.0|[0.78573045256923...|\n",
      "|  tvMovie|   291.0|            97|        Drama|      0|       0.0|[0.82592702059783...|\n",
      "|  tvMovie|   633.0|            95|        Drama|      0|       0.0|[0.76447050510495...|\n",
      "|    movie| 94447.0|           100|       Comedy|      0|       0.0|[0.68080164900481...|\n",
      "|    movie|   374.0|            88|       Comedy|      0|       0.0|[0.90844666296962...|\n",
      "|    movie|  1234.0|            93|       Comedy|      0|       0.0|[0.92882709528281...|\n",
      "|    movie|   348.0|            98|       Comedy|      0|       0.0|[0.91365523445816...|\n",
      "|    movie|   681.0|           100|       Comedy|      0|       0.0|[0.91025825293077...|\n",
      "|    movie|   370.0|           102|       Comedy|      0|       0.0|[0.89308370267420...|\n",
      "|    movie|  3023.0|           111|       Comedy|      0|       0.0|[0.87167990707713...|\n",
      "|    movie|   835.0|            91|       Comedy|      0|       0.0|[0.94231414724697...|\n",
      "|    movie|  2015.0|           100|       Comedy|      0|       0.0|[0.93133789061789...|\n",
      "|    movie|  2747.0|            80|       Comedy|      0|       0.0|[0.91083496244927...|\n",
      "|    movie|   446.0|            95|       Comedy|      0|       0.0|[0.83362665277373...|\n",
      "|    movie|  1120.0|            94|       Comedy|      0|       0.0|[0.91015865647557...|\n",
      "|    movie|   549.0|            93|       Comedy|      0|       0.0|[0.75198450108892...|\n",
      "|    movie|   404.0|           105|       Comedy|      0|       0.0|[0.70799437223609...|\n",
      "|    movie|   532.0|            87|       Comedy|      0|       1.0|[0.32451934997640...|\n",
      "|    movie|   291.0|            78|       Comedy|      0|       0.0|[0.95686732129674...|\n",
      "|    movie|   914.0|            99|       Comedy|      0|       0.0|[0.88395105498851...|\n",
      "|    movie|   547.0|            70|       Comedy|      0|       0.0|[0.85357740402290...|\n",
      "|    movie|   825.0|            85|       Comedy|      0|       0.0|[0.76520718980531...|\n",
      "| tvSeries|  1354.0|            21|       Comedy|      0|       0.0|[0.53009142745156...|\n",
      "| tvSeries|  2939.0|            21|       Comedy|      0|       1.0|[0.49246451157240...|\n",
      "| tvSeries|   273.0|            45|       Comedy|      0|       0.0|[0.52812483602813...|\n",
      "|    movie|   479.0|            89|Drama,Romance|      0|       0.0|[0.85364159004322...|\n",
      "|    movie| 22501.0|           113|Drama,Romance|      0|       0.0|[0.74509722490665...|\n",
      "|    movie|  7657.0|           113|Drama,Romance|      0|       0.0|[0.88293783066747...|\n",
      "|    movie|  1573.0|            98|Drama,Romance|      0|       0.0|[0.85985449228760...|\n",
      "|    movie|  1503.0|            92|Drama,Romance|      0|       0.0|[0.83147388358323...|\n",
      "|    movie|   422.0|            94|Drama,Romance|      0|       0.0|[0.82832454302124...|\n",
      "|    movie|  6260.0|           132|Drama,Romance|      0|       0.0|[0.82904540898674...|\n",
      "|    movie|  3192.0|           116|Drama,Romance|      0|       0.0|[0.66020691598336...|\n",
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test.select('titleType','numVotes','runTimeMinutes','genres', 'Success','prediction', 'probability').show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate our model on the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Area Under ROC 0.9021086939117737\n",
      "Testing Data Area Under ROC 0.7422534410486209\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Training Data Area Under ROC', evaluator.evaluate(pred_train))\n",
    "print('Testing Data Area Under ROC', evaluator.evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Terms\n",
    "\n",
    "True Positive (TP): Correctly predicted to be a positive class.\n",
    "False Positive (FP): Incorrectly predicted to be a positive class.\n",
    "True Negative (TN): Correctly predicted to not be a positive class.\n",
    "False Negative (FN): Incorrectly predicted to not be a positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 469,\n",
       "             Row(label=0.0, prediction=1.0): 112,\n",
       "             Row(label=1.0, prediction=0.0): 135,\n",
       "             Row(label=1.0, prediction=1.0): 198})"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred_test = pred_test.select('label', 'prediction')\n",
    "label_pred_test.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = 198/(198+135)\n",
    "Accuracy =  (198+469)/(198+469+112+135)\n",
    "Precision = 198/(198+112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.5945945945945946\n",
      "Accuracy 0.7297592997811816\n",
      "Precision 0.6387096774193548\n"
     ]
    }
   ],
   "source": [
    "print ('Recall',Recall)\n",
    "print ('Accuracy', Accuracy)\n",
    "print ('Precision', Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, it looks like our model has performed fairly well with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use the Random Forest classifier to see if we can get a better model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n",
    "rfpred_train = rfModel.transform(train)\n",
    "rfpred_test = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "|titleType|numVotes|runTimeMinutes|       genres|Success|prediction|         probability|\n",
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "|    movie|   441.0|            78|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|   585.0|            90|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|   290.0|            98|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|  2293.0|           100|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|   789.0|           106|        Drama|      0|       0.0|[0.67952735048602...|\n",
      "|    movie|   270.0|           106|        Drama|      0|       0.0|[0.67952735048602...|\n",
      "|    movie|   464.0|            85|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|   772.0|            87|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|  3594.0|            90|        Drama|      0|       0.0|[0.68298865718746...|\n",
      "|    movie| 94563.0|           133|        Drama|      0|       0.0|[0.67097629943497...|\n",
      "|    movie|   547.0|            95|        Drama|      0|       0.0|[0.69153970823851...|\n",
      "|    movie|  2086.0|           108|        Drama|      0|       0.0|[0.67952735048602...|\n",
      "|    movie|   414.0|           131|        Drama|      0|       0.0|[0.67952735048602...|\n",
      "|    movie|   300.0|            95|        Drama|      0|       0.0|[0.67623718004909...|\n",
      "|    movie|   352.0|           119|        Drama|      0|       0.0|[0.67952735048602...|\n",
      "| tvSeries|  1504.0|            60|        Drama|      0|       0.0|[0.55246727260411...|\n",
      "|  tvMovie|   308.0|            84|        Drama|      0|       0.0|[0.63477905576272...|\n",
      "|  tvMovie|   312.0|            80|        Drama|      0|       0.0|[0.63477905576272...|\n",
      "|  tvMovie|   291.0|            97|        Drama|      0|       0.0|[0.63477905576272...|\n",
      "|  tvMovie|   633.0|            95|        Drama|      0|       0.0|[0.63477905576272...|\n",
      "|    movie| 94447.0|           100|       Comedy|      0|       0.0|[0.68895868413043...|\n",
      "|    movie|   374.0|            88|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  1234.0|            93|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   348.0|            98|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   681.0|           100|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   370.0|           102|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  3023.0|           111|       Comedy|      0|       0.0|[0.67694632637794...|\n",
      "|    movie|   835.0|            91|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  2015.0|           100|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  2747.0|            80|       Comedy|      0|       0.0|[0.68895868413043...|\n",
      "|    movie|   446.0|            95|       Comedy|      0|       0.0|[0.68965022693508...|\n",
      "|    movie|  1120.0|            94|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   549.0|            93|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   404.0|           105|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   532.0|            87|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   291.0|            78|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   914.0|            99|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   547.0|            70|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   825.0|            85|       Comedy|      0|       0.0|[0.69750973518148...|\n",
      "| tvSeries|  1354.0|            21|       Comedy|      0|       0.0|[0.54236232158800...|\n",
      "| tvSeries|  2939.0|            21|       Comedy|      0|       0.0|[0.54391622155306...|\n",
      "| tvSeries|   273.0|            45|       Comedy|      0|       0.0|[0.52977174187785...|\n",
      "|    movie|   479.0|            89|Drama,Romance|      0|       0.0|[0.69750973518148...|\n",
      "|    movie| 22501.0|           113|Drama,Romance|      0|       0.0|[0.67694632637794...|\n",
      "|    movie|  7657.0|           113|Drama,Romance|      0|       0.0|[0.67694632637794...|\n",
      "|    movie|  1573.0|            98|Drama,Romance|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  1503.0|            92|Drama,Romance|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|   422.0|            94|Drama,Romance|      0|       0.0|[0.69750973518148...|\n",
      "|    movie|  6260.0|           132|Drama,Romance|      0|       0.0|[0.67694632637794...|\n",
      "|    movie|  3192.0|           116|Drama,Romance|      0|       0.0|[0.67694632637794...|\n",
      "+---------+--------+--------------+-------------+-------+----------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfpred_test.select('titleType','numVotes','runTimeMinutes','genres', 'Success','prediction', 'probability').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Area Under ROC 0.7729119527066031\n",
      "Test Area Under ROC 0.7181854832457242\n"
     ]
    }
   ],
   "source": [
    "print('Train Area Under ROC', evaluator.evaluate(rfpred_train))\n",
    "print('Test Area Under ROC', evaluator.evaluate(rfpred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the confusion matrix to calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 572,\n",
       "             Row(label=0.0, prediction=1.0): 9,\n",
       "             Row(label=1.0, prediction=0.0): 302,\n",
       "             Row(label=1.0, prediction=1.0): 31})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_rfpred_test = rfpred_test.select('label', 'prediction')\n",
    "label_rfpred_test.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfRecall = 31/(31+302)\n",
    "rfAccuracy =  (572+31)/(572+9+302+31)\n",
    "rfPrecision = 31/(31+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.09309309309309309\n",
      "Accuracy 0.6597374179431073\n",
      "Precision 0.775\n"
     ]
    }
   ],
   "source": [
    "print ('Recall',rfRecall)\n",
    "print ('Accuracy', rfAccuracy)\n",
    "print ('Precision', rfPrecision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis above, we can conclude that the Logistic regression model has performed much better than the Random Forest. The Random forest model has a tendency to overfit the data, and due to the fact that we only have a few thousand observations, it could be probable to conclude that this might not be the best model to deploy. \n",
    "\n",
    "The logistic regression has performed mucch better, based on the metrics shown above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
